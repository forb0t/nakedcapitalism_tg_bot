"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å—Ç–∞—Ç–µ–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Teletype
"""

import requests
import re
from datetime import datetime
from bs4 import BeautifulSoup
from teletype_converter import TeletypeConverter
import time

class ArticleProcessor(TeletypeConverter):
    def __init__(self):
        super().__init__()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
    
    def fetch_article_content(self, url):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏"""
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏
            content_selectors = [
                'div.entry-content',
                'div.post-content',
                'div.article-content',
                'div.content',
                'article',
                'main'
            ]
            
            article_content = None
            for selector in content_selectors:
                article_content = soup.select_one(selector)
                if article_content:
                    break
            
            if not article_content:
                # Fallback: –ø–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
                article_content = soup.find('div', class_=re.compile(r'content|entry|post|article'))
            
            if article_content:
                # –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                content_text = self.extract_text_content(article_content)
                return content_text
            else:
                return None
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏ {url}: {e}")
            return None
    
    def extract_text_content(self, soup_element):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ HTML —ç–ª–µ–º–µ–Ω—Ç–∞"""
        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for element in soup_element.find_all(['script', 'style', 'nav', 'footer', 'header', 'aside']):
            element.decompose()
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–ª–∞—Å—Å–∞–º–∏ —Ä–µ–∫–ª–∞–º—ã
        for element in soup_element.find_all(class_=re.compile(r'ads|advertisement|sponsor|promo')):
            element.decompose()
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        text_content = soup_element.get_text(separator='\n', strip=True)
        
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        lines = text_content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if line and len(line) > 10:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def create_full_teletype_post(self, article_id):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞ Teletype —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º"""
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç–∞—Ç—å–µ
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT title, url, author, date_posted
            FROM articles 
            WHERE id = ?
        ''', (article_id,))
        
        article_data = cursor.fetchone()
        if not article_data:
            return None
        
        article = {
            'title': article_data[0],
            'url': article_data[1],
            'author': article_data[2],
            'date_posted': article_data[3]
        }
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏
        print(f"üì° –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏: {article['title']}")
        full_content = self.fetch_article_content(article['url'])
        
        if full_content:
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            enhanced_content = self.create_enhanced_teletype_content(article, full_content)
            
            # –ë–∞–∑–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            teletype_post = self.format_teletype_post(article)
            
            # –ó–∞–º–µ–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π
            teletype_post['content'] = enhanced_content
            teletype_post['metadata']['has_full_content'] = True
            teletype_post['metadata']['content_length'] = len(full_content)
            
            return teletype_post
        else:
            # –í–æ–∑–≤—Ä–∞—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø–æ—Å—Ç–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            teletype_post = self.format_teletype_post(article)
            teletype_post['metadata']['has_full_content'] = False
            return teletype_post
    
    def create_enhanced_teletype_content(self, article, full_content):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è Teletype"""
        
        content_parts = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        content_parts.append(f"# {article['title']}")
        content_parts.append("")
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        content_parts.append("## üì∞ Article Information")
        content_parts.append(f"**Author:** {article['author']}")
        content_parts.append(f"**Date:** {self.format_date(article['date_posted'])}")
        content_parts.append(f"**Source:** {self.extract_domain(article['url'])}")
        content_parts.append("")
        
        # –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ –∞–±–∑–∞—Ü—ã)
        summary = self.extract_summary(full_content)
        if summary:
            content_parts.append("## üìù Summary")
            content_parts.append(summary)
            content_parts.append("")
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
        content_parts.append("## üìñ Full Article")
        content_parts.append(self.format_article_content(full_content))
        content_parts.append("")
        
        # –°—Å—ã–ª–∫–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
        content_parts.append("## üîó References")
        content_parts.append(f"[Read original article on {self.extract_domain(article['url'])}]({article['url']})")
        content_parts.append("")
        
        # –¢–µ–≥–∏
        tags = self.generate_tags(article['title'], article['author'])
        content_parts.append("## üè∑Ô∏è Tags")
        for tag in tags:
            content_parts.append(f"#{tag}")
        content_parts.append("")
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        content_parts.append("---")
        content_parts.append(f"**Original URL:** {article['url']}")
        content_parts.append(f"**Content Length:** {len(full_content)} characters")
        content_parts.append(f"**Converted:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return "\n".join(content_parts)
    
    def extract_summary(self, content, max_sentences=3):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', content)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        valid_sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
        
        if valid_sentences:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            summary_sentences = valid_sentences[:max_sentences]
            return '. '.join(summary_sentences) + '.'
        
        return None
    
    def format_article_content(self, content):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏ –¥–ª—è Teletype"""
        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = content.split('\n\n')
        formatted_paragraphs = []
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if len(paragraph) > 50:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã
                formatted_paragraphs.append(paragraph)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        max_length = 5000  # –ú–∞–∫—Å–∏–º—É–º 5000 —Å–∏–º–≤–æ–ª–æ–≤
        full_content = '\n\n'.join(formatted_paragraphs)
        
        if len(full_content) > max_length:
            full_content = full_content[:max_length] + "\n\n*[Content truncated for brevity]*"
        
        return full_content
    
    def process_multiple_articles(self, article_ids, delay=1):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç–∞—Ç–µ–π —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π"""
        processed_articles = []
        
        for i, article_id in enumerate(article_ids, 1):
            print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç—å–∏ {i}/{len(article_ids)} (ID: {article_id})")
            
            article = self.create_full_teletype_post(article_id)
            if article:
                processed_articles.append(article)
                print(f"‚úÖ –°—Ç–∞—Ç—å—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {article['metadata']['title']}")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç—å–∏ ID: {article_id}")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(article_ids):
                time.sleep(delay)
        
        return processed_articles
    
    def batch_convert_latest_articles(self, limit=5, delay=2):
        """–ü–∞–∫–µ—Ç–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT id, title, url, author, date_posted
            FROM articles 
            ORDER BY created_at DESC
            LIMIT ?
        ''', (limit,))
        
        articles_data = cursor.fetchall()
        
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é {len(articles_data)} —Å—Ç–∞—Ç–µ–π")
        
        processed_articles = []
        
        for i, (article_id, title, url, author, date_posted) in enumerate(articles_data, 1):
            print(f"\nüì∞ –°—Ç–∞—Ç—å—è {i}/{len(articles_data)}: {title}")
            
            article = {
                'title': title,
                'url': url,
                'author': author,
                'date_posted': date_posted
            }
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            full_content = self.fetch_article_content(url)
            
            if full_content:
                enhanced_content = self.create_enhanced_teletype_content(article, full_content)
                teletype_post = self.format_teletype_post(article)
                teletype_post['content'] = enhanced_content
                teletype_post['metadata']['has_full_content'] = True
                teletype_post['metadata']['content_length'] = len(full_content)
                
                processed_articles.append(teletype_post)
                print(f"‚úÖ –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω ({len(full_content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            else:
                # –ë–∞–∑–æ–≤—ã–π –ø–æ—Å—Ç –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                teletype_post = self.format_teletype_post(article)
                teletype_post['metadata']['has_full_content'] = False
                processed_articles.append(teletype_post)
                print(f"‚ö†Ô∏è –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω, —Å–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π –ø–æ—Å—Ç")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(articles_data):
                print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {delay} —Å–µ–∫—É–Ω–¥...")
                time.sleep(delay)
        
        return processed_articles

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π"""
    processor = ArticleProcessor()
    
    print("üîÑ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π –¥–ª—è Teletype")
    print("=" * 60)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 2 —Å—Ç–∞—Ç–µ–π —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
    print("üì° –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º...")
    articles = processor.batch_convert_latest_articles(limit=2, delay=3)
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π")
    
    for i, article in enumerate(articles, 1):
        print(f"\nüì∞ –°—Ç–∞—Ç—å—è {i}:")
        print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {article['metadata']['title']}")
        print(f"   –ê–≤—Ç–æ—Ä: {article['metadata']['author']}")
        print(f"   –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {'–î–∞' if article['metadata'].get('has_full_content') else '–ù–µ—Ç'}")
        if article['metadata'].get('content_length'):
            print(f"   –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {article['metadata']['content_length']} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {article['metadata']['category']}")
        print(f"   –¢–µ–≥–∏: {', '.join(article['metadata']['tags'][:5])}")
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ñ–∞–π–ª
    filename = processor.export_to_teletype_format(articles, 'enhanced_teletype_export.json')
    print(f"\nüíæ –°—Ç–∞—Ç—å–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    if articles and articles[0]['metadata'].get('has_full_content'):
        print(f"\nüìù –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–µ—Ä–≤–æ–π —Å—Ç–∞—Ç—å–∏:")
        print("-" * 60)
        content_preview = articles[0]['content'][:800] + "..." if len(articles[0]['content']) > 800 else articles[0]['content']
        print(content_preview)
    
    processor.close()
    print("\n‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main()
